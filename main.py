import cv2
import mediapipe as mp
import sys
import time
import warnings
from collections import deque

# Import c√°c module x·ª≠ l√Ω
from utils.feature_extraction import extract_features
from utils.strings import ExpressionHandler
from utils.tts import TextToSpeech
from utils.model import ASLClassificationModel
from utils.post_processing import PredictionSmoother
from config import MODEL_NAME, MODEL_CONFIDENCE, SMOOTHING_WINDOW_SIZE, CONFIDENCE_THRESHOLD

import streamlit as st

# B·ªè qua c√°c c·∫£nh b√°o kh√¥ng c·∫ßn thi·∫øt
warnings.filterwarnings("ignore")

# ==========================================
# 1. C·∫§U H√åNH GIAO DI·ªÜN STREAMLIT
# ==========================================
st.set_page_config(page_title="ASL Recognition App", layout="wide")

st.markdown("""
    <style>
        .big-font {
            color: #e76f51 !important;
            font-size: 50px !important;
            font-weight: bold;
            border: 2px solid #fcbf49;
            border-radius: 10px;
            padding: 10px;
            text-align: center;
            background-color: #ffffff;
        }
        /* CƒÉn gi·ªØa video */
        div.stImage {
            text-align: center;
        }
    </style>
""", unsafe_allow_html=True)

# ==========================================
# 2. H√ÄM LOAD MODEL (CACHE ƒê·ªÇ TƒÇNG T·ªêC)
# ==========================================
@st.cache_resource
def load_ai_model():
    """Load model m·ªôt l·∫ßn duy nh·∫•t ƒë·ªÉ tr√°nh lag khi reload"""
    print("Loading model...")
    return ASLClassificationModel.load_model(f"models/{MODEL_NAME}")

# Load model ngay khi v√†o app
try:
    model = load_ai_model()
except Exception as e:
    st.error(f"L·ªói kh√¥ng t√¨m th·∫•y model: {e}")
    st.stop()

# ==========================================
# 3. SIDEBAR & C·∫§U H√åNH
# ==========================================
st.sidebar.title("üîß B·∫£ng ƒêi·ªÅu Khi·ªÉn")

# N√öT QUAN TR·ªåNG: B·∫¨T/T·∫ÆT CAMERA
# Checkbox n√†y ƒë√≥ng vai tr√≤ nh∆∞ c√¥ng t·∫Øc ngu·ªìn
run_camera = st.sidebar.checkbox("üì∑ B·∫≠t Camera", value=True)

# C·∫•u h√¨nh ƒë·ªô nh·∫°y AI
st.sidebar.markdown("---")
st.sidebar.subheader("ƒê·ªô nh·∫°y AI (Threshold)")
detection_confidence = st.sidebar.slider("Min Detection Confidence", 0.0, 1.0, MODEL_CONFIDENCE, 0.05)
tracking_confidence = st.sidebar.slider("Min Tracking Confidence", 0.0, 1.0, MODEL_CONFIDENCE, 0.05)

# C·∫•u h√¨nh TTS (Gi·ªçng n√≥i)
st.sidebar.markdown("---")
st.sidebar.subheader("üîä C·∫•u h√¨nh Gi·ªçng n√≥i")
tts_enabled = st.sidebar.checkbox("B·∫≠t ƒë·ªçc k·∫øt qu·∫£", value=False)
tts_engine_choice = st.sidebar.selectbox("C√¥ng c·ª• ƒë·ªçc", ["pyttsx3 (Offline)", "gTTS (Vietnamese, Online)"], index=0)
min_interval = st.sidebar.slider("Kho·∫£ng c√°ch gi·ªØa c√°c l·∫ßn ƒë·ªçc (s)", 1.0, 5.0, 2.0, 0.5)

# X·ª≠ l√Ω TTS Voice ID (n·∫øu d√πng pyttsx3)
tts_voice = None
if "pyttsx3" in tts_engine_choice:
    tts_voice = st.sidebar.text_input("Voice ID (pyttsx3 - Optional)", value="") or None

# Kh·ªüi t·∫°o TTS Session
if 'tts' not in st.session_state:
    st.session_state.tts = None
    st.session_state.tts_engine = None

desired_engine = 'pyttsx3' if 'pyttsx3' in tts_engine_choice else 'gtts'

# Logic kh·ªüi t·∫°o/hu·ª∑ TTS
if tts_enabled:
    # N·∫øu ch∆∞a c√≥ TTS ho·∫∑c ƒë·ªïi engine th√¨ kh·ªüi t·∫°o l·∫°i
    if st.session_state.tts is None or st.session_state.tts_engine != desired_engine:
        try:
            with st.spinner("ƒêang kh·ªüi t·∫°o gi·ªçng n√≥i..."):
                st.session_state.tts = TextToSpeech(engine=desired_engine, lang='vi', voice=tts_voice)
                st.session_state.tts_engine = desired_engine
        except Exception as e:
            st.sidebar.error(f"L·ªói TTS: {e}")
            tts_enabled = False
elif not tts_enabled and st.session_state.tts is not None:
    # T·∫Øt TTS n·∫øu ng∆∞·ªùi d√πng b·ªè ch·ªçn
    try:
        st.session_state.tts.stop()
    except:
        pass
    st.session_state.tts = None

# ==========================================
# 4. GIAO DI·ªÜN CH√çNH
# ==========================================
col1, col2 = st.columns([3, 2])

with col1:
    st.markdown("### üé• Camera Feed")
    video_placeholder = st.empty()

with col2:
    st.markdown("### üìù K·∫øt qu·∫£ D·ª± ƒëo√°n")
    prediction_placeholder = st.empty()
    
    st.markdown("#### ƒê·ªô tin c·∫≠y")
    confidence_bar = st.progress(0)
    confidence_text = st.empty()

    st.markdown("#### L·ªãch s·ª≠")
    history_placeholder = st.empty()

    # Khu v·ª±c hi·ªÉn th·ªã FPS v√† th√¥ng s·ªë
    st.markdown("---")
    fps_display = st.empty()

# ==========================================
# 5. LOGIC X·ª¨ L√ù CAMERA (LOOP)
# ==========================================
if run_camera:
    # Kh·ªüi t·∫°o Mediapipe
    mp_holistic = mp.solutions.holistic
    mp_face_mesh = mp.solutions.face_mesh
    mp_hands = mp.solutions.hands
    mp_drawing = mp.solutions.drawing_utils
    mp_drawing_styles = mp.solutions.drawing_styles

    # M·ªü Camera
    cap = cv2.VideoCapture(0)
    
    expression_handler = ExpressionHandler()
    smoother = PredictionSmoother(window_size=SMOOTHING_WINDOW_SIZE)
    prev_time = 0 # D√πng ƒë·ªÉ t√≠nh FPS
    
    # History buffer
    prediction_history = deque(maxlen=5)

    # S·ª≠ d·ª•ng 'with' ƒë·ªÉ t·ª± ƒë·ªông gi·∫£i ph√≥ng t√†i nguy√™n Mediapipe khi t·∫Øt loop
    with mp_face_mesh.FaceMesh(
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=detection_confidence,
            min_tracking_confidence=tracking_confidence) as face_mesh, \
         mp_hands.Hands(
            max_num_hands=2,
            min_detection_confidence=detection_confidence,
            min_tracking_confidence=tracking_confidence) as hands:

        while cap.isOpened() and run_camera:
            success, image = cap.read()
            if not success:
                st.warning("Kh√¥ng t√¨m th·∫•y camera ho·∫∑c camera ƒëang b·∫≠n.")
                break

            # T√≠nh to√°n FPS
            curr_time = time.time()
            fps = 1 / (curr_time - prev_time)
            prev_time = curr_time
            fps_display.metric("FPS T·ªëc ƒë·ªô x·ª≠ l√Ω", f"{int(fps)}")

            # X·ª≠ l√Ω h√¨nh ·∫£nh
            image.flags.writeable = False
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # 1. Detect Faces & Hands
            face_results = face_mesh.process(image)
            hand_results = hands.process(image)

            # 2. V·∫Ω l√™n h√¨nh
            image.flags.writeable = True
            # V·∫Ω Face
            if face_results.multi_face_landmarks:
                for face_landmarks in face_results.multi_face_landmarks:
                    mp_drawing.draw_landmarks(
                        image=image,
                        landmark_list=face_landmarks,
                        connections=mp_face_mesh.FACEMESH_TESSELATION,
                        landmark_drawing_spec=None,
                        connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=1)
                    )
            # V·∫Ω Hands
            if hand_results.multi_hand_landmarks:
                for hand_landmarks in hand_results.multi_hand_landmarks:
                    mp_drawing.draw_landmarks(
                        image=image,
                        landmark_list=hand_landmarks,
                        connections=mp_hands.HAND_CONNECTIONS,
                        landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),
                        connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2)
                    )

            # 3. D·ª± ƒëo√°n c·ª≠ ch·ªâ
            try:
                # Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng (D√πng h√†m m·ªõi nh·∫•t c·ªßa b·∫°n)
                feature = extract_features(mp_hands, face_results, hand_results)
                
                # ƒê∆∞a v√†o model
                # expression = model.predict(feature) # C≈©
                label, confidence = model.predict_with_confidence(feature)
                
                # Th√™m v√†o b·ªô l√†m m∆∞·ª£t
                smoother.add_prediction(label, confidence)
                smoothed_label, smoothed_confidence = smoother.get_smoothed_prediction()

                # Logic hi·ªÉn th·ªã
                ui_text = "..."
                if smoothed_confidence >= CONFIDENCE_THRESHOLD:
                    expression_handler.receive(smoothed_label)
                    ui_text = expression_handler.get_message()
                    
                    # C·∫≠p nh·∫≠t history n·∫øu c√≥ thay ƒë·ªïi
                    if not prediction_history or prediction_history[-1] != ui_text:
                        prediction_history.append(ui_text)
                else:
                    ui_text = "..." # Kh√¥ng ch·∫Øc ch·∫Øn

                # Hi·ªÉn th·ªã Text
                prediction_placeholder.markdown(f'<div class="big-font">{ui_text}</div>', unsafe_allow_html=True)
                
                # Hi·ªÉn th·ªã Confidence
                confidence_bar.progress(min(smoothed_confidence, 1.0))
                confidence_text.text(f"ƒê·ªô tin c·∫≠y: {round(smoothed_confidence * 100, 1)}%")
                
                # Hi·ªÉn th·ªã History
                history_html = "<ul>" + "".join([f"<li>{item}</li>" for item in prediction_history]) + "</ul>"
                history_placeholder.markdown(history_html, unsafe_allow_html=True)

                # ƒê·ªçc gi·ªçng n√≥i
                if tts_enabled and st.session_state.tts and smoothed_confidence >= CONFIDENCE_THRESHOLD:
                    speech_text = expression_handler.get_speech_message()
                    st.session_state.tts.speak_if_allowed(speech_text, min_interval=min_interval)

            except Exception as e:
                print(f"Prediction error: {e}")

            # Hi·ªÉn th·ªã h√¨nh ·∫£nh l√™n Web
            video_placeholder.image(image, channels="RGB", use_column_width=True)

    # Gi·∫£i ph√≥ng camera khi tho√°t v√≤ng l·∫∑p
    cap.release()
    cv2.destroyAllWindows()

else:
    # Giao di·ªán khi Camera T·∫Øt
    st.info("Camera ƒëang t·∫Øt. T√≠ch v√†o √¥ 'üì∑ B·∫≠t Camera' ·ªü thanh b√™n tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    video_placeholder.empty()
    prediction_placeholder.empty()
    fps_display.empty()